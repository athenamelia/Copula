---
title: "MLE for nested Archimedean copulas"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{my-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(ncopula)
```

### Abstract

The package ncopula provides procedures for calculating maximum likelihood estimation for nested Archimedean copulas including multiple families and rotation copulas in any dimensions. This will expand to include selection of nested Archimedean copula nesting structure and an evaluation of a nested Archimedean copulas random forest model. 

Keywords: Archimedean copulas, nested Archimedean copulas, rotation copulas, random forest


### Description of copulas:

Copula is a multivariate distribution function with standard uniform univariate margins $U(0,1)$ margins. The distribution function H of a d-dimensional random vector $X = (X_{1}, ..., X_{d})$ is defined
$H(x) = P(X \leq x) = P(X_{1} \leq x_{1},..., X_{d} \leq x_{d})$, $x = (x_{1},..., x_{d}) \in R^{d}.$

The standard uniform univariate df $F_{j}$ of $X_{j}, j \in \{1, ..., d\}$, can be obtained from the multivariate df H by $F_{j} = H(\infty,...,\infty,x_{j},\infty,...,\infty), x_{j} \in R$. Thus, $F_{1},...,F_{d}$ are also called the $univariate \space margins$ or the $marginal \space dfs$ of $X$. 

The code is adapted from Hofert_2018_Book_ElementsOfCopulaModelingWithR. 
```{r}
# Scatter plots of n = 1000 independent observations of the bivariate random vectors (X1,X2)
wine_red <- read.csv("data/wine_red.csv")
wine_red_df <- as.data.frame(wine_red)
wine_red <- wine_red_df[-c(1296, 1297), -12]
X <- as.matrix(wine_red_df)[, c(1, 2)]
plot(X, xlab = quote(X*''[1]), ylab = quote(X*''[2]))
```

```{r}
# figures
n <- nrow(X)
U <- cbind(pnorm(X[,1], mean = mean(X[,1]),
                 sd = sqrt((n-1)/n) * sd(X[,1]), log = FALSE),
           pnorm(X[,2], mean = mean(X[,2]),
                 sd = sqrt((n-1)/n) * sd(X[,2]), log = FALSE))
plot(U, xlab = quote(U*""[1]), ylab = quote(U*""[2]))
```

### How the joint cdf and pdf of the data are calculated using a copula
The multivariate df H is calculated via
$H(x) = P(X \leq x) = P(X_{1} \leq x_{1},..., X_{d} \leq x_{d})$, $x = (x_{1},..., x_{d}) \in R^{d}.$
$H(x) = C(F_{1}(x_{1}),...,F_{d}(x_{d}), x \in R^{d}$

where copula $C$ represents the dependence structure of the variables and $F_{1},...,F_{d}$ represents univariate marginals which can be obtained from $F_{j}(x_{j}) = H(\infty,...,\infty,x_{j},\infty,...,\infty), x_{j} \in R$.

The density c of a copula C is calculated via
$c(u) = \frac{\partial^d}{\partial u_{d}...\partial u_{1}}C(u_{1},...,u_{d}), u \in (0,1)^{d}$

```{r}
library(copula)
d <- 2
ic <- indepCopula(dim = d)
set.seed(2019)
u <- runif(d) # a random point in the unit hypercube
pCopula(u, copula = ic) # the copula value at u - cdf
# surface plot of the ic
wireframe2(ic, FUN = pCopula, col.4 = adjustcolor("black", alpha.f = 0.25))
contourplot2(ic, FUN = pCopula) # contour plot of the ic
```

For data with nonparametrically estimated margins $F_{1},...,F_{d}$, the unknow univariate marginal dfs are estimated by the (rescaled) empirical dfs of the component sample of $X_{1},...,X_{n}$.

Specifically, for any $j \in \{1,...,d\}, F_{j}$ is estimated by 

$F_{n,j}(x) = \frac{1}{n+1}\Sigma_{i=1}^{n}1(X_{ij}\leq x), x \in R.$

The estimated margins are used to form sample 
$U_{i,n} = (F_{n,1}(X_{i1}),...,F_{n,d}(X_{id})), i \in \{1,...,n\}$

$U_{i,n}$ is a sample of $pseudo-observations$ from C. 

1) A single variable X_1 with values on the horizontal axis, show pdf and cdf (two vertically aligned sub-figures), with a sample of values of X_{i1},... X_{in} along the horizontal axis and their correspnding pseudo-obs U_{i1}, ... U_{in} along the vertical axis in the cdf plot. 

2) For a pair of variables (X_1, X_2), show a scatter plot of samples (X_{i1}, X_{i2}) drawn from their joint distribution and what corresponding pairs (U_{i1}, U_{i2}) look like. Pick a few observations to highlight, to show where they fall within a large sample. 
